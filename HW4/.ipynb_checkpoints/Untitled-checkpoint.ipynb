{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266fc97d-5359-4bc8-8a44-978ba2f16ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# ~~ Part 2 ~~\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mmake_mean_image_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlarge_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# ~~ Part 3 ~~\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Change this line! standardize large_dataset and store the result in large_dataset_standardized\u001b[39;00m\n\u001b[1;32m    163\u001b[0m std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(large_dataset, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mmake_mean_image_plot\u001b[0;34m(data, standardized)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(niters):\n\u001b[1;32m    130\u001b[0m     KMeansClassifier \u001b[38;5;241m=\u001b[39m KMeans(K\u001b[38;5;241m=\u001b[39mK, runs\u001b[38;5;241m=\u001b[39mruns)\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mKMeansClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     allmeans[:,i] \u001b[38;5;241m=\u001b[39m KMeansClassifier\u001b[38;5;241m.\u001b[39mget_mean_images()\n\u001b[1;32m    133\u001b[0m     alllosses[:,i] \u001b[38;5;241m=\u001b[39m KMeansClassifier\u001b[38;5;241m.\u001b[39mget_losses()\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruns):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Assign datapoints to nearest cluster\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massignment[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Update cluster means\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/courses/am120/env/lib/python3.9/site-packages/numpy/linalg/linalg.py:2546\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m add\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mabs\u001b[39m(x), axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims)\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# special case for speedup\u001b[39;00m\n\u001b[0;32m-> 2546\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m)\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(add\u001b[38;5;241m.\u001b[39mreduce(s, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims))\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;66;03m# are valid for vectors\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CS 181, Spring 2022\n",
    "# Homework 4\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading datasets for K-Means and HAC\n",
    "small_dataset = np.load(\"data/small_dataset.npy\")\n",
    "large_dataset = np.load(\"data/large_dataset.npy\")\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# NOTE: You may need to add more helper functions to these classes\n",
    "class KMeans(object):\n",
    "    # K is the K in KMeans\n",
    "    def __init__(self, K, runs):\n",
    "        self.K = K\n",
    "        self.means = None\n",
    "        self.runs = runs\n",
    "        self.assignment = None\n",
    "        self.losses = np.zeros(runs)\n",
    "        self.title = \"KMeans\"\n",
    "\n",
    "    # X is a (N x 784) array since the dimension of each image is 28x28.\n",
    "    def fit(self, X):\n",
    "        # Initialize cluster assignment and random centers\n",
    "        self.assignment = np.zeros(X.shape[0])\n",
    "        self.means = np.random.randn(self.K, X.shape[1])\n",
    "\n",
    "        for run in range(self.runs):\n",
    "            # Assign datapoints to nearest cluster\n",
    "            for i, x in enumerate(X):\n",
    "                self.assignment[i] = np.argmin(np.linalg.norm(x - self.means, axis=1) ** 2)\n",
    "\n",
    "            # Update cluster means\n",
    "            for k in range(self.K):\n",
    "                clusteroid = X[self.assignment == k]\n",
    "                if clusteroid.size != 0:\n",
    "                    self.means[k] = clusteroid.mean(axis=0)\n",
    "            \n",
    "            # Record loss\n",
    "            self.losses[run] = self.__objective(X)\n",
    "        return\n",
    "\n",
    "    # This should return the arrays for K images. Each image should represent the mean of each of the fitted clusters.\n",
    "    def get_mean_images(self):\n",
    "        return self.means\n",
    "    \n",
    "    def get_losses(self):\n",
    "        return self.losses\n",
    "\n",
    "    def get_assignment(self):\n",
    "        return self.assignment\n",
    "    \n",
    "    def __objective(self, X):\n",
    "        return np.sum([np.linalg.norm(x - self.means[int(self.assignment[i])]) ** 2 for i, x in enumerate(X)])\n",
    "\n",
    "class HAC(object):\n",
    "    def __init__(self, linkage):\n",
    "        self.linkage = linkage\n",
    "        self.assignments = []\n",
    "        self.X = None\n",
    "        self.title = f\"HAC with {linkage} linkage\"\n",
    "    \n",
    "    # X is a (N x 784) array since the dimension of each image is 28x28.\n",
    "    def fit(self, X):\n",
    "        # Store X\n",
    "        self.X = X\n",
    "\n",
    "        # Create initial cluster assignment\n",
    "        N = X.shape[0]\n",
    "        assignment = np.arange(N)\n",
    "        self.assignments.append(np.copy(assignment))\n",
    "\n",
    "        # Perform clustering\n",
    "        nclusters = N\n",
    "        merged = set()\n",
    "        while nclusters > 1:\n",
    "            # Find nearest clusters\n",
    "            midx, mval = [0, 1], float('inf')\n",
    "            for i in range(N):\n",
    "                for j in range(i+1, N):\n",
    "                    if i in merged or j in merged:\n",
    "                        continue\n",
    "\n",
    "                    Xi, Xj = X[assignment == i], X[assignment == j]\n",
    "                    m = 0\n",
    "                    if self.linkage == 'centroid':\n",
    "                        m = np.linalg.norm(Xi.mean(axis=0) - Xj.mean(axis=0))\n",
    "                    elif self.linkage == 'min':\n",
    "                        m = np.min(cdist(Xi, Xj))\n",
    "                    else:\n",
    "                        m = np.max(cdist(Xi, Xj))\n",
    "\n",
    "                    if m < mval:\n",
    "                        mval = m\n",
    "                        midx = [i, j]\n",
    "\n",
    "            # Merge clusters\n",
    "            assignment[assignment == midx[1]] = midx[0]\n",
    "            merged.add(midx[1])\n",
    "            self.assignments.append(np.copy(assignment))\n",
    "            nclusters -= 1\n",
    "\n",
    "        return\n",
    "\n",
    "    # Returns the mean image when using n_clusters clusters\n",
    "    def get_mean_images(self, n_clusters):\n",
    "        means = np.zeros((n_clusters, self.X.shape[1]))\n",
    "        assignment = self.assignments[-n_clusters]\n",
    "        clusters = np.unique(assignment)\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            means[i] = self.X[assignment == cluster].mean(axis=0)\n",
    "        return means\n",
    "\n",
    "    def get_assignment(self, n_clusters=10):\n",
    "        return self.assignments[-n_clusters]\n",
    "\n",
    "# Plotting code for parts 2 and 3\n",
    "def make_mean_image_plot(data, standardized=False):\n",
    "    # Number of random restarts\n",
    "    niters = 3\n",
    "    runs = 10\n",
    "    K = 10\n",
    "    # Will eventually store the pixel representation of all the mean images across restarts\n",
    "    allmeans = np.zeros((K, niters, 784))\n",
    "    alllosses = np.zeros((K, runs))\n",
    "    for i in range(niters):\n",
    "        KMeansClassifier = KMeans(K=K, runs=runs)\n",
    "        KMeansClassifier.fit(data)\n",
    "        allmeans[:,i] = KMeansClassifier.get_mean_images()\n",
    "        alllosses[:,i] = KMeansClassifier.get_losses()\n",
    "    \n",
    "    # Plot losses\n",
    "    fig = plt.figure()\n",
    "    for i in range(niters):\n",
    "        plt.plot(alllosses[:,i], label=f'Run {i}')\n",
    "    plt.title('Losses on each run')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.suptitle('Class mean images across random restarts' + (' (standardized data)' if standardized else ''), fontsize=16)\n",
    "    for k in range(K):\n",
    "        for i in range(niters):\n",
    "            ax = fig.add_subplot(K, niters, 1+niters*k+i)\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "            ax.tick_params(axis='both', which='both', length=0)\n",
    "            if k == 0: plt.title('Iter '+str(i))\n",
    "            if i == 0: ax.set_ylabel('Class '+str(k), rotation=90)\n",
    "            plt.imshow(allmeans[k,i].reshape(28,28), cmap='Greys_r')\n",
    "    plt.show()\n",
    "\n",
    "# ~~ Part 2 ~~\n",
    "make_mean_image_plot(large_dataset, False)\n",
    "\n",
    "# ~~ Part 3 ~~\n",
    "# Change this line! standardize large_dataset and store the result in large_dataset_standardized\n",
    "std = np.std(large_dataset, axis=0)\n",
    "std[std == 0] = 1\n",
    "large_dataset_standardized = (large_dataset - large_dataset.mean(axis=0)) / std\n",
    "make_mean_image_plot(large_dataset_standardized, True)\n",
    "\n",
    "# Plotting code for part 4\n",
    "LINKAGES = [ 'max', 'min', 'centroid' ]\n",
    "n_clusters = 10\n",
    "\n",
    "hacs = []\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.suptitle(\"HAC mean images with max, min, and centroid linkages\")\n",
    "for l_idx, l in enumerate(LINKAGES):\n",
    "    # Fit HAC\n",
    "    hac = HAC(l)\n",
    "    hac.fit(small_dataset)\n",
    "    mean_images = hac.get_mean_images(n_clusters)\n",
    "    hacs.append(hac)\n",
    "    # Make plot\n",
    "    for m_idx in range(mean_images.shape[0]):\n",
    "        m = mean_images[m_idx]\n",
    "        ax = fig.add_subplot(n_clusters, len(LINKAGES), l_idx + m_idx*len(LINKAGES) + 1)\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.tick_params(axis='both', which='both', length=0)\n",
    "        if m_idx == 0: plt.title(l)\n",
    "        if l_idx == 0: ax.set_ylabel('Class '+str(m_idx), rotation=90)\n",
    "        plt.imshow(m.reshape(28,28), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7037796-0c65-430d-a75d-b0424257271f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d879e7-2dfe-47dd-b2ed-cc2de2e2af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cluster sizes for each HAC linkage\n",
    "for hac in hacs:\n",
    "    _, counts = np.unique(hac.assignments[-n_clusters], return_counts=True)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(counts, '.')\n",
    "    plt.title(f'HAC cluster counts with {hac.linkage} linkage')\n",
    "    plt.xlabel('Cluster index')\n",
    "    plt.ylabel('Number of images in cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5813a-da5c-45b7-b4a3-1e1ca6f4521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the most common abbreviation of 'seaborn'\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "def cluster_map(arr):\n",
    "    return { v : k for k, v in dict(enumerate(arr)).items() }\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "KMeansClassifier = KMeans(K=10, runs=10)\n",
    "KMeansClassifier.fit(small_dataset)\n",
    "\n",
    "K = 10\n",
    "methods = [KMeansClassifier] + hacs\n",
    "for m1, m2 in itertools.combinations(methods, 2):\n",
    "    # Create confusion matrix\n",
    "    a1, a2 = m1.get_assignment(), m2.get_assignment()\n",
    "    a1m, a2m = cluster_map(np.unique(a1)), cluster_map(np.unique(a2))\n",
    "    N = a1.shape[0]\n",
    "    C = np.zeros((K, K))\n",
    "    for i in range(N):\n",
    "        C[a1m[a1[i]], a2m[a2[i]]] += 1\n",
    "\n",
    "    sns.heatmap(C)\n",
    "\n",
    "    # we can also add titles and labels\n",
    "    plt.xlabel(m1.title)\n",
    "    plt.ylabel(m2.title)\n",
    "    plt.title(f\"Heatmap of {m1.title} vs {m2.title}\")\n",
    "\n",
    "    # beautify, save, and show\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f5a66-c2e4-4516-ad89-db1e5fe3bca1",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "## Part 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb23cdb-ba83-4539-bb50-2d40aa3d97d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3. 30.]\n",
      " [-2.  0.]\n",
      " [-1. -2.]\n",
      " [ 0.  0.]\n",
      " [ 1. -2.]\n",
      " [ 2.  0.]\n",
      " [ 3. 30.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = np.array([\n",
    "    [-3, 1],\n",
    "    [-2, 1],\n",
    "    [-1, -1],\n",
    "    [0, 1],\n",
    "    [1, -1],\n",
    "    [2, 1],\n",
    "    [3, 1]\n",
    "])\n",
    "X, y = D[:,0], D[:,1]\n",
    "\n",
    "def basis(X):\n",
    "    Phi = np.zeros((X.size, 2))\n",
    "    Phi[:,0] = np.copy(X)\n",
    "    Phi[:,1] = (-8 / 3) * (X ** 2) + (2 / 3) * (X ** 4)\n",
    "    return Phi\n",
    "\n",
    "X = basis(X)\n",
    "\n",
    "print(X)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(X[y == 1][:, 0], X[y == 1][:, 1], '.')\n",
    "plt.plot(X[y == -1][:, 0], X[y == -1][:, 1], 'x')\n",
    "plt.title('Transformed training data')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$-\\frac{8}{3} x^2 + \\frac{2}{3} x^4$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b2665de-b417-4e39-9821-22c4ea1ee784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3. 30.]\n",
      " [-2.  0.]\n",
      " [-1. -2.]\n",
      " [ 0.  0.]\n",
      " [ 1. -2.]\n",
      " [ 2.  0.]\n",
      " [ 3. 30.]]\n",
      "[-2.]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0],[2]])\n",
    "w0 = 2\n",
    "\n",
    "print(X)\n",
    "\n",
    "print(w.T@X[2] + w0)\n",
    "\n",
    "def boundary(x):\n",
    "    return w.T@x + w0\n",
    "\n",
    "# plt.figure()\n",
    "# plt.clf()\n",
    "# p = boundary(np.arange(-3, 3, 0.1))\n",
    "# plt.plot(p)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27ad7f-b5e2-4590-8c39-e30e9f5a3c1d",
   "metadata": {},
   "source": [
    "## Part 1.2\n",
    "\n",
    "Value of the margin is 1.\n",
    "\n",
    "## Part 1.3\n",
    "\n",
    "Decision boundary is a horizontal line, so an orthogonal vector is $(0, 1)$.\n",
    "\n",
    "## Part 1.4\n",
    "\n",
    "From 1.3 we know that w must be some scalar of $[0, 1]$, so $\\textbf{w} = c [0, 1]$. We know that the decision boundary is $0$ only when $\\phi_2 = -1$. Using this information:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\textbf{w} \\phi + w_0 &= 0 \\\\\n",
    "  c [0, 1]^T \\phi + w_0 &= 0 \\\\\n",
    "  c (0) \\phi_1 + c (1) \\phi_2 + w_0 &= 0 \\\\\n",
    "  c \\phi_2 + w_0 &= 0 \\\\\n",
    "  c (-1) + w_0 &= 0 \\\\\n",
    "  c &= w_0\n",
    "\\end{align*}\n",
    "$$\n",
    "And so the optimal decision boundary occurs when $\\textbf{w} = [0, w_0]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b9693-31bd-40ef-a869-57a7701de89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-3, 3, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca089562-d008-4479-b3f3-e9906ae7faef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
